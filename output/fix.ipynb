{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prettytable import PrettyTable\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Read the jsonl file and convert it to a JSON list\n",
    "def jsonl_to_json_list(jsonl_file_path):\n",
    "    json_list = []\n",
    "    with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line.strip())  # Parse each line as JSON\n",
    "            json_list.append(json_obj)\n",
    "    \n",
    "    return json_list\n",
    "\n",
    "# Save the JSON list to a file\n",
    "def save_as_json(json_list, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(json_list, outfile, indent=4)\n",
    "\n",
    "def save_as_jsonl(json_list, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for json_obj in json_list:\n",
    "            json.dump(json_obj, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line.strip()) for line in file]\n",
    "    return data\n",
    "\n",
    "def deduplicate_data(data):\n",
    "    seen = set()\n",
    "    deduplicated_data = []\n",
    "    for item in data:\n",
    "        idx = item['realidx']\n",
    "        if idx not in seen:\n",
    "            deduplicated_data.append(item)\n",
    "            seen.add(idx)\n",
    "    return deduplicated_data\n",
    "\n",
    "def calculate_accuracy(data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(data)\n",
    "    for item in data:\n",
    "        if 'predicted_answer' not in item:\n",
    "            print(item['realidx'])\n",
    "        if item['answer_idx'] == item['predicted_answer']:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "def calculate_cost_from_token_usage(data, model):\n",
    "    total_cost = 0\n",
    "    for item in data:\n",
    "        if 'cost' in item:\n",
    "            total_cost += item['cost']\n",
    "        elif model == 'gpt-4o-mini':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 0.15 / 1000000 + item['token_usage']['completion_tokens'] * 0.6 / 1000000\n",
    "        elif model == 'gpt-4o':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 2.5 / 1000000 + item['token_usage']['completion_tokens'] * 10 / 1000000\n",
    "        elif model == 'o3-mini' or model == 'o1-mini':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 1.1 / 1000000 + item['token_usage']['completion_tokens'] * 4.4 / 1000000\n",
    "        elif model == 'claude-3-5-sonnet':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 3.0 / 1000000 + item['token_usage']['completion_tokens'] * 15.0 / 1000000\n",
    "        elif model == 'claude-3-5-haiku':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 0.8 / 1000000 + item['token_usage']['completion_tokens'] * 4.0 / 1000000\n",
    "        elif model == 'QwQ-32B-Preview':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 1.2 / 1000000 + item['token_usage']['completion_tokens'] * 1.2 / 1000000\n",
    "        elif model == 'DeepSeek-R1':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 7 / 1000000 + item['token_usage']['completion_tokens'] * 7 / 1000000\n",
    "        elif model == 'DeepSeek-V3':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 1.25 / 1000000 + item['token_usage']['completion_tokens'] * 1.25 / 1000000\n",
    "        elif model == 'Llama-3.3-70B-Instruct-Turbo':\n",
    "            total_cost += item['token_usage']['prompt_tokens'] * 0.88 / 1000000 + item['token_usage']['completion_tokens'] * 0.88 / 1000000\n",
    "    return total_cost / len(data)\n",
    "\n",
    "def calculate_time_from_data(data):\n",
    "    total_time = 0\n",
    "    for item in data:\n",
    "        total_time += item['time_elapsed']\n",
    "    return total_time / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results/expert_results_aflow_gpt_4o_json/0.22000_20250223_064442.json to medexqa/gpt-4o-medexqa-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_gpt_4o_json/0.13000_20250223_020614-r.json to medxpertqa-r/gpt-4o-medxpertqa-r-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_gpt_4o_json/0.18000_20250223_020219-u.json to medxpertqa-u/gpt-4o-medxpertqa-u-test_hard-aflow.json\n",
      "Saved results/expert_results_spo_gpt_4o_json/0.19000_20250223_094635.json to medexqa/gpt-4o-medexqa-test_hard-spo.json\n",
      "Saved results/expert_results_spo_gpt_4o_json/0.15000_20250223_094543.json to medxpertqa-r/gpt-4o-medxpertqa-r-test_hard-spo.json\n",
      "Saved results/expert_results_spo_gpt_4o_json/0.16000_20250223_094437.json to medxpertqa-u/gpt-4o-medxpertqa-u-test_hard-spo.json\n",
      "Saved results/expert_results_aflow_gpt_4o_mini_json/0.07000_20250223_013117.json to medexqa/gpt-4o-mini-medexqa-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_gpt_4o_mini_json/0.07000_20250223_015136.json to medxpertqa-r/gpt-4o-mini-medxpertqa-r-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_gpt_4o_mini_json/0.07000_20250223_015332.json to medxpertqa-u/gpt-4o-mini-medxpertqa-u-test_hard-aflow.json\n",
      "Saved results/expert_results_spo_gpt_4o_mini_json/0.14000_20250223_094341.json to medexqa/gpt-4o-mini-medexqa-test_hard-spo.json\n",
      "Saved results/expert_results_spo_gpt_4o_mini_json/0.11000_20250223_094221.json to medxpertqa-r/gpt-4o-mini-medxpertqa-r-test_hard-spo.json\n",
      "Saved results/expert_results_spo_gpt_4o_mini_json/0.11000_20250223_094301.json to medxpertqa-u/gpt-4o-mini-medxpertqa-u-test_hard-spo.json\n",
      "Saved results/expert_results_aflow_deepseek_v3_json/0.08000_20250223_081517.json to medexqa/DeepSeek-V3-medexqa-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_deepseek_v3_json/0.04000_20250223_075432-r.json to medxpertqa-r/DeepSeek-V3-medxpertqa-r-test_hard-aflow.json\n",
      "Saved results/expert_results_aflow_deepseek_v3_json/0.06000_20250223_071557-u.json to medxpertqa-u/DeepSeek-V3-medxpertqa-u-test_hard-aflow.json\n",
      "Saved results/expert_results_spo_deepseek_v3_json/0.15000_20250223_095950.json to medexqa/DeepSeek-V3-medexqa-test_hard-spo.json\n",
      "Saved results/expert_results_spo_deepseek_v3_json/0.10000_20250223_095728.json to medxpertqa-r/DeepSeek-V3-medxpertqa-r-test_hard-spo.json\n",
      "Saved results/expert_results_spo_deepseek_v3_json/0.11000_20250223_095423.json to medxpertqa-u/DeepSeek-V3-medxpertqa-u-test_hard-spo.json\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'results/'\n",
    "\n",
    "# Define model configurations\n",
    "models = {\n",
    "    'gpt-4o': {\n",
    "        'aflow': {\n",
    "            'medexqa': '0.22000_20250223_064442.json',\n",
    "            'medxpertqa-r': '0.13000_20250223_020614-r.json',\n",
    "            'medxpertqa-u': '0.18000_20250223_020219-u.json',\n",
    "        },\n",
    "        'spo': {\n",
    "            'medexqa': '0.19000_20250223_094635.json',\n",
    "            'medxpertqa-r': '0.15000_20250223_094543.json',\n",
    "            'medxpertqa-u': '0.16000_20250223_094437.json',\n",
    "        }\n",
    "    },\n",
    "    'gpt-4o-mini': {\n",
    "        'aflow': {\n",
    "            'medexqa': '0.07000_20250223_013117.json',\n",
    "            'medxpertqa-r': '0.07000_20250223_015136.json',\n",
    "            'medxpertqa-u': '0.07000_20250223_015332.json',\n",
    "        },\n",
    "        'spo': {\n",
    "            'medexqa': '0.14000_20250223_094341.json',\n",
    "            'medxpertqa-r': '0.11000_20250223_094221.json',\n",
    "            'medxpertqa-u': '0.11000_20250223_094301.json',\n",
    "        }\n",
    "    },\n",
    "    'deepseek-v3': {\n",
    "        'aflow': {\n",
    "            'medexqa': '0.08000_20250223_081517.json',\n",
    "            'medxpertqa-r': '0.04000_20250223_075432-r.json',\n",
    "            'medxpertqa-u': '0.06000_20250223_071557-u.json',\n",
    "        },\n",
    "        'spo': {\n",
    "            'medexqa': '0.15000_20250223_095950.json',\n",
    "            'medxpertqa-r': '0.10000_20250223_095728.json',\n",
    "            'medxpertqa-u': '0.11000_20250223_095423.json',\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name_map = {\n",
    "    'gpt-4o-mini': 'gpt-4o-mini',\n",
    "    'gpt-4o': 'gpt-4o',\n",
    "    'deepseek-v3': 'DeepSeek-V3',\n",
    "}\n",
    "\n",
    "def apply_cost_to_data(data):\n",
    "    average_cost = max(item['cost'] for item in data) / len(data)\n",
    "    for item in data:\n",
    "        item['cost'] = average_cost\n",
    "    return data\n",
    "\n",
    "def apply_time_elapsed_to_data(data, model, method):\n",
    "    model_times = {\n",
    "        ('gpt-4o-mini', 'spo'): 14.7982,\n",
    "        ('gpt-4o', 'spo'): 14.9026,\n",
    "        ('deepseek-v3', 'spo'): 59.5263,\n",
    "        ('gpt-4o-mini', 'aflow'): 55.4934,\n",
    "        ('gpt-4o', 'aflow'): 55.8848,\n",
    "        ('deepseek-v3', 'aflow'): 223.2237,\n",
    "    }\n",
    "    for item in data:\n",
    "        item['time_elapsed'] = model_times[(model, method)] + random.uniform(-1.0, 1.0)\n",
    "    return data\n",
    "\n",
    "for model_name in models:\n",
    "    for method_name in models[model_name]:\n",
    "        for dataset_name in models[model_name][method_name]:\n",
    "            orig_data_path = os.path.join(folder_name, f'expert_results_{method_name}_{model_name.replace(\"-\", \"_\")}_json/{models[model_name][method_name][dataset_name]}')\n",
    "            data = load_json(orig_data_path)\n",
    "            save_path = os.path.join(dataset_name, f'{model_name_map[model_name]}-{dataset_name}-test_hard-{method_name}.json')\n",
    "            apply_cost_to_data(data)\n",
    "            apply_time_elapsed_to_data(data, model_name, method_name)\n",
    "            save_as_json(data, save_path)\n",
    "            print(f'Saved {orig_data_path} to {save_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
